{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6eaab858",
   "metadata": {},
   "source": [
    "# Road Scene Understanding with Kitti Dataset\n",
    "#### CS 5190\n",
    "#### Team Members: "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0caa1b2",
   "metadata": {},
   "source": [
    "## SETUP\n",
    "> conda install matplotlib numpy opencv pandas scikit-image scikit-learn scipy ultralytics opencv-python tqdm pillow\n",
    "\n",
    "Each line in a label file contains the following:\n",
    "`<object_type> <truncation> <occlusion> <alpha> <left> <top> <right> <bottom> <height> <width> <length> <x> <y> <z> <rotation_y>`\n",
    "\n",
    "YOLOV8 requires format of 'class x_center y_center width height' -> for each image has one txt file with a single line for each bounding box.\n",
    "Structure for yolov8: https://roboflow.com/formats/yolov8-pytorch-txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "168cfdd8",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe85d3c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# KITTI BASE PATHS\n",
    "full_path_project_folder = INSERT_PATH_HERE\n",
    "base_yolo_path = full_path_project_folder + \"finalProject\\\\yolov8\\\\\"\n",
    "base_labels_path = full_path_project_folder + \"finalProject\\\\data_object_label_2\\\\training\\\\label_2\\\\\"\n",
    "base_images_train_path = full_path_project_folder + \"finalProject\\\\data_object_image_2\\\\training\\\\image_2\\\\\"\n",
    "\n",
    "# KITTI CLASSES/OBJECT types in the labels file\n",
    "OBJECT_CLASSES = {'Car': 0, 'Van': 1, 'Truck': 2, 'Pedestrian': 3, 'Person_sitting': 4, 'Cyclist': 5, 'Tram': 6, 'Misc': 7, 'DontCare': 8}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3424b044",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "#create pairs for the paths to KITTI images and labels\n",
    "path_pairs = []\n",
    "if not os.path.isdir(base_labels_path):\n",
    "    print(f\"Error: Folder {base_labels_path} not found\")\n",
    "elif not os.path.isdir(base_images_train_path):\n",
    "    print(f\"Error: Folder {base_images_train_path} not found\")\n",
    "else:\n",
    "    for full_filename in os.listdir(base_labels_path):\n",
    "        filename = full_filename.split('.')\n",
    "        pair = {\"img_path\": (base_images_train_path + filename[0] + \".png\"), \"label_path\": (base_labels_path + filename[0] + \".txt\") }\n",
    "        path_pairs.append(pair)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8834cb37",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: Might want to implement train split later on\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#seperate into 80% training and 20% validation\n",
    "train, validate = train_test_split(path_pairs, test_size=0.2, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88ed5f96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'img_path': 'C:\\\\Users\\\\Sabrina Ferras\\\\OneDrive - csumb.edu\\\\Documents\\\\CPP\\\\4Fall2025\\\\CS_5190\\\\finalProject\\\\data_object_image_2\\\\training\\\\image_2\\\\000000.png',\n",
       "  'label_path': 'C:\\\\Users\\\\Sabrina Ferras\\\\OneDrive - csumb.edu\\\\Documents\\\\CPP\\\\4Fall2025\\\\CS_5190\\\\finalProject\\\\data_object_label_2\\\\training\\\\label_2\\\\000000.txt'},\n",
       " {'img_path': 'C:\\\\Users\\\\Sabrina Ferras\\\\OneDrive - csumb.edu\\\\Documents\\\\CPP\\\\4Fall2025\\\\CS_5190\\\\finalProject\\\\data_object_image_2\\\\training\\\\image_2\\\\000001.png',\n",
       "  'label_path': 'C:\\\\Users\\\\Sabrina Ferras\\\\OneDrive - csumb.edu\\\\Documents\\\\CPP\\\\4Fall2025\\\\CS_5190\\\\finalProject\\\\data_object_label_2\\\\training\\\\label_2\\\\000001.txt'}]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#print a few to see if it worked right\n",
    "path_pairs[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b7471de",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d9de90b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#function that takes in bounding box coordinates from the label file and image width&height \n",
    "#return x_center, y_center, width, and height\n",
    "def convert_bbox_yolo8(img_w, img_h, x1 , y1, x2, y2):\n",
    "    x_center = ((x1 + x2) / 2 ) / img_w\n",
    "    y_center = ((y1 + y2) / 2 ) / img_h\n",
    "    width = (x2 - x1) / img_w\n",
    "    height = (y2 - y1) / img_h\n",
    "\n",
    "    return x_center, y_center, width, height"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "666a7036",
   "metadata": {},
   "outputs": [],
   "source": [
    "for curr_pair in path_pairs:\n",
    "    #set yolo file\n",
    "    yolo_path = base_yolo_path + os.path.basename(curr_pair['label_path'])\n",
    "    \n",
    "    #open image to get width & height\n",
    "    try:\n",
    "        img = Image.open(curr_pair['img_path'])\n",
    "        img_width, img_height = img.size\n",
    "    except Exception as e:\n",
    "        print(f\"Error opening image {curr_pair['img_path']}: {e}\")\n",
    "        continue\n",
    "    \n",
    "    #loop through label file line by line to add to yolo .txt file\n",
    "    with open(curr_pair['label_path']) as f:\n",
    "        lines = f.readlines()\n",
    "    \n",
    "    yolo_lines = []\n",
    "    for line in lines:\n",
    "        label_parts = line.strip().split()\n",
    "        object_name = label_parts[0]\n",
    "        class_id = OBJECT_CLASSES[object_name]\n",
    "        if class_id == 8: continue # excluding the DontCare bounding boxes\n",
    "        bb_x1, bb_y1, bb_x2, bb_y2 = map(float, label_parts[4:8])   #taking original bounding box coordinates from kitti label\n",
    "        x_center, y_center, width, height = convert_bbox_yolo8(img_width, img_height, bb_x1 , bb_y1, bb_x2, bb_y2) \n",
    "        yolo_lines.append(f\"{class_id} {x_center} {y_center} {width} {height}\\n\") #yolo format\n",
    "\n",
    "    #create and write yolo normalized bounding box\n",
    "    with open(yolo_path, \"w\") as out:\n",
    "        out.writelines(yolo_lines)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dedda98",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d795c95f",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3efcf86",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "79b389ac",
   "metadata": {},
   "source": [
    "## Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "101a8081",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cs5190finalproj",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
